---
layout: post
title: "TensorFlare or: How I Learned to Stop Worrying and Love ML"
date: 2017-05-10
---

In our [last]({% post_url 2017-04-14-parquet-on-fire %}) post, we discussed running queries in Apache Spark and Flare using the Parquet data format. In the [posts before that](https://flaredata.github.io#blog), we've looked at various speedups which Flare brings over the current iteration of Spark. In all of these posts, we've viewed Flare as a closed system, designed to operate solely as a data loading/processing tool. However, what sort of speedups could we see by chaining a system like Spark or Flare with an existing machine learning framework (in our case, TensorFlow)?

In this blog post, we examine the possibility of using a "big data" processing engine like Flare in a streamed pipeline with TensorFlow to see what sort of speed gains we can achieve.

## TensorFlow

[TensorFlow](https://www.tensorflow.org/) is, to quote their website, "an open source software library for numerical computation using data flow graphs." Essentially, this boils down to being an extremely efficient machine learning (ML) framework. TensorFlow represents computations as graphs, with nodes representing operations and edges between those nodes representing data. All data in TensorFlow is stored in multidimensional arrays (tensors), which allows TensorFlow to be extremely flexible in where it can be deployed and run.

TensorFlow is extremely efficient (concrete numbers available [here](https://www.tensorflow.org/performance/benchmarks) and [here](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45166.pdf)), in part due to being written in C++. However, APIs are available in Python, Scala, and Java, with Python being the primary target (as evidenced by the [lack of API stability promises for all other languages](https://www.tensorflow.org/api_docs/)).

## PySpark: The Mullet of Data Processing

In keeping with TensorFlow's target usage, we elected to use Spark's Python API, [PySpark](http://spark.apache.org/docs/2.1.0/api/python/pyspark.html). Due to Python's expressive nature and [documented wide usage](https://www.tiobe.com/tiobe-index/), PySpark is a natural extension to lower the barrier of entry for data science professionals by abstracting things even further than Scala -- resulting in a system which allows for users to have nothing but business up front, with a party of performance in the back.

## PyFlare: Mullets Without Regret?

As many computer scientists will attest, abstraction typically comes with performance loss. However, at the core of Flare is a system aimed specifically at providing "abstraction without regret." That is, users should be given a high-level interface, without the associated runtime penalty.

To this end, we hooked the PySpark frontend into our Flare backend, replacing the original SparkSQL API. Thus, we achieve the expressiveness gains offered by PySpark, while retaining the performance gains brough by Flare (documented in our previous blog posts).

It should be noted that both PySpark and PyFlare may contain some inherent latency compared to Spark's native Scala API due to the necessity of using [Py4J](https://www.py4j.org/), but we accept this small performance loss in exchange for using TensorFlow's main API.

## 











once all data has been loaded. However, we encounter a problem similar to that discussed in our [first]({% post_url 2016-09-30-q6-spark-vs-c-on-a-laptop %}) blog post and (somewhat) resolved in our most [recent]({% post_url 2017-04-14-parquet-on-fire %}) post: loading data from disk is extremely slow. 